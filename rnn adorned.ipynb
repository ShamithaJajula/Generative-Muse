{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"X7Stl5izgxhE","outputId":"180d313a-e13b-4228-a1ff-1fef29a56f09"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 10, 100)           320100    \n","                                                                 \n"," lstm (LSTM)                 (None, 10, 128)           117248    \n","                                                                 \n"," dropout (Dropout)           (None, 10, 128)           0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 128)               131584    \n","                                                                 \n"," dense (Dense)               (None, 3201)              412929    \n","                                                                 \n","=================================================================\n","Total params: 981861 (3.75 MB)\n","Trainable params: 981861 (3.75 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/200\n","485/485 [==============================] - 27s 48ms/step - loss: 6.8844 - accuracy: 0.0238\n","Epoch 2/200\n","485/485 [==============================] - 25s 52ms/step - loss: 6.4911 - accuracy: 0.0260\n","Epoch 3/200\n","485/485 [==============================] - 25s 52ms/step - loss: 6.3971 - accuracy: 0.0303\n","Epoch 4/200\n","485/485 [==============================] - 23s 48ms/step - loss: 6.2969 - accuracy: 0.0345\n","Epoch 5/200\n","485/485 [==============================] - 25s 51ms/step - loss: 6.1707 - accuracy: 0.0373\n","Epoch 6/200\n","485/485 [==============================] - 22s 46ms/step - loss: 6.0445 - accuracy: 0.0426\n","Epoch 7/200\n","485/485 [==============================] - 25s 51ms/step - loss: 5.9204 - accuracy: 0.0459\n","Epoch 8/200\n","485/485 [==============================] - 22s 46ms/step - loss: 5.7956 - accuracy: 0.0512\n","Epoch 9/200\n","485/485 [==============================] - 25s 51ms/step - loss: 5.6673 - accuracy: 0.0537\n","Epoch 10/200\n","485/485 [==============================] - 26s 53ms/step - loss: 5.5333 - accuracy: 0.0601\n","Epoch 11/200\n","485/485 [==============================] - 24s 49ms/step - loss: 5.3980 - accuracy: 0.0672\n","Epoch 12/200\n","485/485 [==============================] - 24s 50ms/step - loss: 5.2650 - accuracy: 0.0706\n","Epoch 13/200\n","485/485 [==============================] - 23s 48ms/step - loss: 5.1367 - accuracy: 0.0757\n","Epoch 14/200\n","485/485 [==============================] - 25s 51ms/step - loss: 5.0152 - accuracy: 0.0837\n","Epoch 15/200\n","485/485 [==============================] - 22s 46ms/step - loss: 4.8938 - accuracy: 0.0903\n","Epoch 16/200\n","485/485 [==============================] - 25s 51ms/step - loss: 4.7775 - accuracy: 0.0954\n","Epoch 17/200\n","485/485 [==============================] - 22s 46ms/step - loss: 4.6587 - accuracy: 0.1016\n","Epoch 18/200\n","485/485 [==============================] - 25s 51ms/step - loss: 4.5407 - accuracy: 0.1107\n","Epoch 19/200\n","485/485 [==============================] - 23s 47ms/step - loss: 4.4238 - accuracy: 0.1266\n","Epoch 20/200\n","485/485 [==============================] - 28s 57ms/step - loss: 4.3153 - accuracy: 0.1326\n","Epoch 21/200\n","485/485 [==============================] - 24s 49ms/step - loss: 4.2043 - accuracy: 0.1504\n","Epoch 22/200\n","485/485 [==============================] - 24s 49ms/step - loss: 4.0993 - accuracy: 0.1673\n","Epoch 23/200\n","485/485 [==============================] - 25s 51ms/step - loss: 3.9932 - accuracy: 0.1821\n","Epoch 24/200\n","485/485 [==============================] - 22s 46ms/step - loss: 3.8958 - accuracy: 0.1965\n","Epoch 25/200\n","485/485 [==============================] - 25s 51ms/step - loss: 3.8029 - accuracy: 0.2118\n","Epoch 26/200\n","485/485 [==============================] - 22s 46ms/step - loss: 3.7152 - accuracy: 0.2285\n","Epoch 27/200\n","485/485 [==============================] - 25s 51ms/step - loss: 3.6277 - accuracy: 0.2426\n","Epoch 28/200\n","485/485 [==============================] - 22s 45ms/step - loss: 3.5448 - accuracy: 0.2571\n","Epoch 29/200\n","485/485 [==============================] - 24s 50ms/step - loss: 3.4705 - accuracy: 0.2696\n","Epoch 30/200\n","485/485 [==============================] - 25s 51ms/step - loss: 3.3947 - accuracy: 0.2854\n","Epoch 31/200\n","485/485 [==============================] - 24s 50ms/step - loss: 3.3251 - accuracy: 0.2955\n","Epoch 32/200\n","485/485 [==============================] - 23s 47ms/step - loss: 3.2581 - accuracy: 0.3057\n","Epoch 33/200\n","485/485 [==============================] - 23s 47ms/step - loss: 3.1902 - accuracy: 0.3202\n","Epoch 34/200\n","485/485 [==============================] - 24s 50ms/step - loss: 3.1254 - accuracy: 0.3297\n","Epoch 35/200\n","485/485 [==============================] - 22s 45ms/step - loss: 3.0687 - accuracy: 0.3388\n","Epoch 36/200\n","485/485 [==============================] - 24s 49ms/step - loss: 3.0052 - accuracy: 0.3502\n","Epoch 37/200\n","485/485 [==============================] - 22s 44ms/step - loss: 2.9480 - accuracy: 0.3624\n","Epoch 38/200\n","485/485 [==============================] - 24s 49ms/step - loss: 2.8954 - accuracy: 0.3748\n","Epoch 39/200\n","485/485 [==============================] - 22s 45ms/step - loss: 2.8408 - accuracy: 0.3816\n","Epoch 40/200\n","485/485 [==============================] - 24s 49ms/step - loss: 2.7888 - accuracy: 0.3931\n","Epoch 41/200\n","485/485 [==============================] - 25s 51ms/step - loss: 2.7389 - accuracy: 0.3998\n","Epoch 42/200\n","485/485 [==============================] - 23s 46ms/step - loss: 2.6889 - accuracy: 0.4118\n","Epoch 43/200\n","485/485 [==============================] - 23s 47ms/step - loss: 2.6371 - accuracy: 0.4237\n","Epoch 44/200\n","485/485 [==============================] - 22s 46ms/step - loss: 2.5893 - accuracy: 0.4309\n","Epoch 45/200\n","485/485 [==============================] - 24s 50ms/step - loss: 2.5498 - accuracy: 0.4402\n","Epoch 46/200\n","485/485 [==============================] - 21s 44ms/step - loss: 2.5013 - accuracy: 0.4496\n","Epoch 47/200\n","485/485 [==============================] - 24s 49ms/step - loss: 2.4608 - accuracy: 0.4617\n","Epoch 48/200\n","485/485 [==============================] - 22s 45ms/step - loss: 2.4144 - accuracy: 0.4665\n","Epoch 49/200\n","485/485 [==============================] - 24s 49ms/step - loss: 2.3749 - accuracy: 0.4756\n","Epoch 50/200\n","485/485 [==============================] - 21s 44ms/step - loss: 2.3356 - accuracy: 0.4831\n","Epoch 51/200\n","485/485 [==============================] - 26s 54ms/step - loss: 2.2921 - accuracy: 0.4917\n","Epoch 52/200\n","485/485 [==============================] - 23s 47ms/step - loss: 2.2590 - accuracy: 0.5010\n","Epoch 53/200\n","485/485 [==============================] - 23s 48ms/step - loss: 2.2203 - accuracy: 0.5096\n","Epoch 54/200\n","485/485 [==============================] - 23s 48ms/step - loss: 2.1797 - accuracy: 0.5151\n","Epoch 55/200\n","485/485 [==============================] - 22s 46ms/step - loss: 2.1465 - accuracy: 0.5254\n","Epoch 56/200\n","485/485 [==============================] - 24s 49ms/step - loss: 2.1140 - accuracy: 0.5337\n","Epoch 57/200\n","485/485 [==============================] - 22s 45ms/step - loss: 2.0806 - accuracy: 0.5413\n","Epoch 58/200\n","485/485 [==============================] - 24s 50ms/step - loss: 2.0441 - accuracy: 0.5493\n","Epoch 59/200\n","485/485 [==============================] - 22s 45ms/step - loss: 2.0103 - accuracy: 0.5556\n","Epoch 60/200\n","485/485 [==============================] - 24s 50ms/step - loss: 1.9804 - accuracy: 0.5566\n","Epoch 61/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.9556 - accuracy: 0.5638\n","Epoch 62/200\n","485/485 [==============================] - 26s 54ms/step - loss: 1.9085 - accuracy: 0.5765\n","Epoch 63/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.8849 - accuracy: 0.5850\n","Epoch 64/200\n","485/485 [==============================] - 24s 50ms/step - loss: 1.8619 - accuracy: 0.5838\n","Epoch 65/200\n","485/485 [==============================] - 22s 46ms/step - loss: 1.8292 - accuracy: 0.5936\n","Epoch 66/200\n","485/485 [==============================] - 24s 50ms/step - loss: 1.8012 - accuracy: 0.5990\n","Epoch 67/200\n","485/485 [==============================] - 23s 47ms/step - loss: 1.7772 - accuracy: 0.6032\n","Epoch 68/200\n","485/485 [==============================] - 23s 48ms/step - loss: 1.7427 - accuracy: 0.6113\n","Epoch 69/200\n","485/485 [==============================] - 23s 48ms/step - loss: 1.7155 - accuracy: 0.6184\n","Epoch 70/200\n","485/485 [==============================] - 23s 47ms/step - loss: 1.6935 - accuracy: 0.6262\n","Epoch 71/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.6665 - accuracy: 0.6296\n","Epoch 72/200\n","485/485 [==============================] - 24s 50ms/step - loss: 1.6450 - accuracy: 0.6334\n","Epoch 73/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.6234 - accuracy: 0.6401\n","Epoch 74/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.6007 - accuracy: 0.6423\n","Epoch 75/200\n","485/485 [==============================] - 24s 50ms/step - loss: 1.5731 - accuracy: 0.6528\n","Epoch 76/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.5518 - accuracy: 0.6561\n","Epoch 77/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.5279 - accuracy: 0.6622\n","Epoch 78/200\n","485/485 [==============================] - 22s 44ms/step - loss: 1.5039 - accuracy: 0.6673\n","Epoch 79/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.4822 - accuracy: 0.6724\n","Epoch 80/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.4706 - accuracy: 0.6731\n","Epoch 81/200\n","485/485 [==============================] - 23s 48ms/step - loss: 1.4440 - accuracy: 0.6799\n","Epoch 82/200\n","485/485 [==============================] - 26s 54ms/step - loss: 1.4241 - accuracy: 0.6839\n","Epoch 83/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.4080 - accuracy: 0.6872\n","Epoch 84/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.3886 - accuracy: 0.6917\n","Epoch 85/200\n","485/485 [==============================] - 22s 44ms/step - loss: 1.3676 - accuracy: 0.6981\n","Epoch 86/200\n","485/485 [==============================] - 24s 50ms/step - loss: 1.3492 - accuracy: 0.7010\n","Epoch 87/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.3388 - accuracy: 0.7036\n","Epoch 88/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.3179 - accuracy: 0.7063\n","Epoch 89/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.3050 - accuracy: 0.7083\n","Epoch 90/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.2818 - accuracy: 0.7148\n","Epoch 91/200\n","485/485 [==============================] - 22s 44ms/step - loss: 1.2691 - accuracy: 0.7202\n","Epoch 92/200\n","485/485 [==============================] - 26s 54ms/step - loss: 1.2554 - accuracy: 0.7206\n","Epoch 93/200\n","485/485 [==============================] - 22s 44ms/step - loss: 1.2429 - accuracy: 0.7200\n","Epoch 94/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.2287 - accuracy: 0.7276\n","Epoch 95/200\n","485/485 [==============================] - 21s 44ms/step - loss: 1.2051 - accuracy: 0.7329\n","Epoch 96/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.1926 - accuracy: 0.7349\n","Epoch 97/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.1825 - accuracy: 0.7352\n","Epoch 98/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.1673 - accuracy: 0.7384\n","Epoch 99/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.1500 - accuracy: 0.7423\n","Epoch 100/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.1354 - accuracy: 0.7471\n","Epoch 101/200\n","485/485 [==============================] - 22s 46ms/step - loss: 1.1287 - accuracy: 0.7475\n","Epoch 102/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.1104 - accuracy: 0.7528\n","Epoch 103/200\n","485/485 [==============================] - 26s 53ms/step - loss: 1.1031 - accuracy: 0.7531\n","Epoch 104/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.0970 - accuracy: 0.7510\n","Epoch 105/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.0857 - accuracy: 0.7561\n","Epoch 106/200\n","485/485 [==============================] - 21s 44ms/step - loss: 1.0699 - accuracy: 0.7585\n","Epoch 107/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.0626 - accuracy: 0.7592\n","Epoch 108/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.0485 - accuracy: 0.7635\n","Epoch 109/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.0425 - accuracy: 0.7636\n","Epoch 110/200\n","485/485 [==============================] - 22s 45ms/step - loss: 1.0256 - accuracy: 0.7659\n","Epoch 111/200\n","485/485 [==============================] - 24s 49ms/step - loss: 1.0239 - accuracy: 0.7654\n","Epoch 112/200\n","485/485 [==============================] - 22s 44ms/step - loss: 1.0037 - accuracy: 0.7730\n","Epoch 113/200\n","485/485 [==============================] - 26s 53ms/step - loss: 0.9952 - accuracy: 0.7755\n","Epoch 114/200\n","485/485 [==============================] - 22s 45ms/step - loss: 0.9961 - accuracy: 0.7733\n","Epoch 115/200\n","485/485 [==============================] - 24s 49ms/step - loss: 0.9794 - accuracy: 0.7778\n","Epoch 116/200\n","485/485 [==============================] - 23s 47ms/step - loss: 0.9747 - accuracy: 0.7806\n","Epoch 117/200\n","485/485 [==============================] - 23s 48ms/step - loss: 0.9689 - accuracy: 0.7782\n","Epoch 118/200\n","485/485 [==============================] - 23s 48ms/step - loss: 0.9601 - accuracy: 0.7833\n","Epoch 119/200\n","485/485 [==============================] - 23s 46ms/step - loss: 0.9408 - accuracy: 0.7857\n","Epoch 120/200\n","485/485 [==============================] - 24s 50ms/step - loss: 0.9386 - accuracy: 0.7846\n","Epoch 121/200\n","485/485 [==============================] - 22s 45ms/step - loss: 0.9301 - accuracy: 0.7842\n","Epoch 122/200\n","485/485 [==============================] - 24s 50ms/step - loss: 0.9227 - accuracy: 0.7877\n","Epoch 123/200\n","485/485 [==============================] - 22s 45ms/step - loss: 0.9110 - accuracy: 0.7870\n","Epoch 124/200\n","485/485 [==============================] - 27s 55ms/step - loss: 0.9140 - accuracy: 0.7880\n","Epoch 125/200\n","485/485 [==============================] - 24s 49ms/step - loss: 0.9040 - accuracy: 0.7912\n","Epoch 126/200\n","485/485 [==============================] - 23s 48ms/step - loss: 0.8954 - accuracy: 0.7940\n","Epoch 127/200\n","485/485 [==============================] - 24s 50ms/step - loss: 0.8845 - accuracy: 0.7955\n","Epoch 128/200\n","485/485 [==============================] - 22s 46ms/step - loss: 0.8778 - accuracy: 0.7956\n","Epoch 129/200\n","485/485 [==============================] - 25s 51ms/step - loss: 0.8734 - accuracy: 0.7974\n","Epoch 130/200\n","485/485 [==============================] - 22s 46ms/step - loss: 0.8776 - accuracy: 0.7959\n","Epoch 131/200\n","485/485 [==============================] - 25s 51ms/step - loss: 0.8636 - accuracy: 0.7973\n","Epoch 132/200\n","485/485 [==============================] - 24s 49ms/step - loss: 0.8625 - accuracy: 0.7989\n","Epoch 133/200\n","485/485 [==============================] - 24s 49ms/step - loss: 0.8534 - accuracy: 0.7993\n","Epoch 134/200\n","485/485 [==============================] - 27s 55ms/step - loss: 0.8391 - accuracy: 0.8030\n","Epoch 135/200\n","485/485 [==============================] - 22s 46ms/step - loss: 0.8396 - accuracy: 0.8040\n","Epoch 136/200\n","485/485 [==============================] - 25s 51ms/step - loss: 0.8327 - accuracy: 0.8038\n","Epoch 137/200\n","485/485 [==============================] - 22s 45ms/step - loss: 0.8262 - accuracy: 0.8089\n","Epoch 138/200\n","485/485 [==============================] - 25s 51ms/step - loss: 0.8270 - accuracy: 0.8058\n","Epoch 139/200\n","485/485 [==============================] - 22s 46ms/step - loss: 0.8187 - accuracy: 0.8054\n","Epoch 140/200\n","485/485 [==============================] - 24s 50ms/step - loss: 0.8127 - accuracy: 0.8105\n","Epoch 141/200\n","485/485 [==============================] - 23s 48ms/step - loss: 0.8111 - accuracy: 0.8089\n","Epoch 142/200\n","485/485 [==============================] - 23s 48ms/step - loss: 0.8016 - accuracy: 0.8112\n","Epoch 143/200\n","485/485 [==============================] - 25s 51ms/step - loss: 0.8002 - accuracy: 0.8094\n","Epoch 144/200\n","485/485 [==============================] - 24s 49ms/step - loss: 0.7891 - accuracy: 0.8136\n","Epoch 145/200\n","485/485 [==============================] - 25s 51ms/step - loss: 0.7811 - accuracy: 0.8147\n","Epoch 146/200\n","485/485 [==============================] - 23s 47ms/step - loss: 0.7801 - accuracy: 0.8157\n","Epoch 147/200\n","485/485 [==============================] - 24s 50ms/step - loss: 0.7810 - accuracy: 0.8132\n","Epoch 148/200\n","485/485 [==============================] - 24s 50ms/step - loss: 0.7761 - accuracy: 0.8165\n","Epoch 149/200\n","485/485 [==============================] - 22s 46ms/step - loss: 0.7704 - accuracy: 0.8148\n","Epoch 150/200\n","485/485 [==============================] - 24s 51ms/step - loss: 0.7657 - accuracy: 0.8158\n","Epoch 151/200\n","485/485 [==============================] - 21s 44ms/step - loss: 0.7648 - accuracy: 0.8160\n","Epoch 152/200\n","485/485 [==============================] - 25s 51ms/step - loss: 0.7585 - accuracy: 0.8180\n","Epoch 153/200\n"," 69/485 [===>..........................] - ETA: 17s - loss: 0.6783 - accuracy: 0.8379"]}],"source":["import pandas as pd\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import utils\n","from textblob import TextBlob\n","import nltk\n","\n","nltk.download('vader_lexicon')\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Load the text data\n","text = open('/content/drive/My Drive/shakespeare.txt').read().splitlines()\n","# Tokenization\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(text)\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","# Generate input sequences\n","input_sequences = []\n","for sent in text:\n","    sequence = tokenizer.texts_to_sequences([sent])[0]\n","    for j in range(1, len(sequence)):\n","        n_gram = sequence[:j+1]\n","        input_sequences.append(n_gram)\n","\n","max_len = max([len(i) for i in input_sequences])\n","input_sequences = pad_sequences(input_sequences, maxlen=max_len)\n","\n","# Preparing input and labels\n","inputs = input_sequences[:, :-1]\n","labels = input_sequences[:, -1]\n","labels = utils.to_categorical(labels, num_classes=vocab_size)\n","# Build the model\n","model = Sequential([\n","    Embedding(vocab_size, 100, input_length=max_len-1),\n","    LSTM(128, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(128),\n","    Dense(vocab_size, activation='softmax')\n","])\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","history = model.fit(inputs, labels, epochs=200)\n","def sentiment_score(text):\n","    sia = SentimentIntensityAnalyzer()\n","    return sia.polarity_scores(text)['compound']\n","\n","def lexical_diversity(text):\n","    words = text.split()\n","    return len(set(words)) / len(words) if words else 0\n","\n","def average_word_length(text):\n","    words = text.split()\n","    return np.mean([len(word) for word in words]) if words else 0\n","\n","def iambic_pentameter_adherence(line):\n","    # Simplified check: 10 syllables with stress on every second syllable\n","    return True  # Placeholder\n","\n","def format_adherence(sonnet):\n","    # Simplified check: 14 lines\n","    return len(sonnet.split('\\n')) == 14\n","def generate_text(initial_text, words_per_line=10, total_lines=14):\n","    new_text = initial_text\n","    sonnet = []\n","    current_line = []\n","    for _ in range(words_per_line * total_lines):\n","        tokens = tokenizer.texts_to_sequences([new_text])\n","        pad_seq = pad_sequences(tokens, maxlen=max_len-1)\n","        preds = model.predict(pad_seq)[0]\n","        next_index = np.argmax(preds)\n","        next_word = tokenizer.index_word.get(next_index, 'unknown')\n","        current_line.append(next_word)\n","        new_text += ' ' + next_word\n","        if len(current_line) >= words_per_line:\n","            sonnet.append(\" \".join(current_line))\n","            current_line = []\n","    full_text = \"\\n\".join(sonnet)\n","    return full_text, sentiment_score(full_text), lexical_diversity(full_text), average_word_length(full_text), format_adherence(full_text)\n","# Example usage\n","generated_text, sentiment, diversity, avg_word_len, adheres_format = generate_text('Adorned in shades of red')\n","print(\"Generated Text:\", generated_text)\n","print(\"Sentiment Score:\", sentiment)\n","print(\"Lexical Diversity:\", diversity)\n","print(\"Average Word Length:\", avg_word_len)\n","print(\"Format Adherence:\", adheres_format)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4LEWmWYg2n6"},"outputs":[],"source":["hours that for thee is afford hate men men cupid\n","heat ' taken set counted me while you deeds still\n","brought his heart of state her shalt grow not and\n","skill away their woe outward brow windows windows so ill\n","cunning outward windows windows windows still while moon twain self\n","brain husbandry cupid call cupid painted one so so me\n","me so short a lease of me not so write\n","so now you much give stay her memory end staineth\n","night still taken ill are ill night i keep aside\n","green a time exchanged day night not tyrannous foes commend\n","doom or store a time exchanged spend taken men so\n","while all ill age ever be away young thine end\n","all me cruel in windows told me green away loving\n","head live live made all the mouths so vanishing decease"]},{"cell_type":"markdown","source":["hours that for thee is afford hate men men cupid\n","heat ' taken set counted me while you deeds still\n","brought his heart of state her shalt grow not and\n","skill away their woe outward brow windows windows so ill\n","cunning outward windows windows windows still while moon twain self\n","brain husbandry cupid call cupid painted one so so me\n","me so short a lease of me not so write\n","so now you much give stay her memory end staineth\n","night still taken ill are ill night i keep aside\n","green a time exchanged day night not tyrannous foes commend\n","doom or store a time exchanged spend taken men so\n","while all ill age ever be away young thine end\n","all me cruel in windows told me green away loving\n","head live live made all the mouths so vanishing decease"],"metadata":{"id":"wWYELOgjYpm4"}}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOrYjyWh2ykZQAmcfhY0CQ7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}