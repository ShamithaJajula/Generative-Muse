{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6__G1lepg-Uh","executionInfo":{"status":"ok","timestamp":1714142042207,"user_tz":-330,"elapsed":83055,"user":{"displayName":"Shamitha Jajula","userId":"18007923260204706759"}},"outputId":"929fd290-6d80-4516-d794-73792b295af0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 10, 100)           320100    \n","                                                                 \n"," gru (GRU)                   (None, 10, 128)           88320     \n","                                                                 \n"," dropout (Dropout)           (None, 10, 128)           0         \n","                                                                 \n"," gru_1 (GRU)                 (None, 128)               99072     \n","                                                                 \n"," dense (Dense)               (None, 3201)              412929    \n","                                                                 \n","=================================================================\n","Total params: 920421 (3.51 MB)\n","Trainable params: 920421 (3.51 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","485/485 [==============================] - 18s 26ms/step - loss: 7.0076 - accuracy: 0.0214\n","Epoch 2/10\n","485/485 [==============================] - 4s 8ms/step - loss: 6.5044 - accuracy: 0.0305\n","Epoch 3/10\n","485/485 [==============================] - 5s 11ms/step - loss: 6.2910 - accuracy: 0.0378\n","Epoch 4/10\n","485/485 [==============================] - 4s 7ms/step - loss: 6.0424 - accuracy: 0.0463\n","Epoch 5/10\n","485/485 [==============================] - 3s 7ms/step - loss: 5.7548 - accuracy: 0.0610\n","Epoch 6/10\n","485/485 [==============================] - 5s 10ms/step - loss: 5.4453 - accuracy: 0.0747\n","Epoch 7/10\n","485/485 [==============================] - 4s 8ms/step - loss: 5.1427 - accuracy: 0.0858\n","Epoch 8/10\n","485/485 [==============================] - 3s 7ms/step - loss: 4.8518 - accuracy: 0.1023\n","Epoch 9/10\n","485/485 [==============================] - 4s 8ms/step - loss: 4.5706 - accuracy: 0.1314\n","Epoch 10/10\n","485/485 [==============================] - 4s 9ms/step - loss: 4.3000 - accuracy: 0.1631\n","1/1 [==============================] - 1s 602ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","to my will be free near cured bark\n","free torn prove me pain me be it\n","seen thee more grow in thee to thee\n","to misuse me defeated bright friend ' lie\n","so you still lie to thee to thee\n","more say mine eye to this blind free\n","rich be one desert thee so so not\n","not be not care to such gone are\n","not in thee you still prove thee who\n","still you feel thee i have belong not\n","see her mind to thee oppressed are shown\n","prove me sun staineth lie art in thee\n","so old old best are be so much\n","so made my heart and be kind in\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GRU, Dense, Embedding, Dropout\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import utils\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","text = open('/content/drive/My Drive/shakespeare.txt').read().splitlines()\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(text)\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","input_sequence = []\n","for sent in text:\n","    sequence = tokenizer.texts_to_sequences([sent])[0]\n","    for j in range(1, len(sequence)):\n","        n_gram = sequence[:j+1]\n","        input_sequence.append(n_gram)\n","\n","max_len = max([len(i) for i in input_sequence])\n","input_sequence = pad_sequences(input_sequence, maxlen=max_len)\n","\n","inputs = input_sequence[:, :-1]\n","labels = input_sequence[:, -1]\n","labels = utils.to_categorical(labels, num_classes=vocab_size)\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, 100, input_length=max_len-1))\n","model.add(GRU(128, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(GRU(128))\n","model.add(Dense(vocab_size, activation='softmax'))\n","model.summary()\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","history = model.fit(inputs, labels, epochs=10)\n","\n","# Function to sample the next word\n","def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds + 1e-10) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","# Generating a new sonnet\n","new_text = 'For your lovers sake'\n","words_per_line = 8\n","total_lines = 14\n","sonnet = []\n","current_line = []\n","\n","for _ in range(words_per_line * total_lines):\n","    tokens = tokenizer.texts_to_sequences([new_text])\n","    pad = pad_sequences(tokens, maxlen=max_len-1)\n","    preds = model.predict(pad)[0]\n","    next_index = sample(preds, temperature=0.5)\n","    next_word = tokenizer.index_word.get(next_index, 'unknown')\n","\n","    current_line.append(next_word)\n","    new_text += ' ' + next_word\n","\n","    if len(current_line) >= words_per_line:\n","        sonnet.append(\" \".join(current_line))\n","        current_line = []\n","\n","for line in sonnet:\n","    print(line)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1ixkOCZ_aqejxAL-JzIg6c6NMxD70EZSw","authorship_tag":"ABX9TyPcALwp3Rw77MONywkMolWw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}