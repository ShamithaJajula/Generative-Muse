{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"1L6FvT8AaU6R","executionInfo":{"status":"ok","timestamp":1717792088546,"user_tz":-330,"elapsed":8160,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout, Bidirectional\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import utils"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42481,"status":"ok","timestamp":1717792133050,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"},"user_tz":-330},"id":"FR8sL6ficKOF","outputId":"20a78e3c-b441-4af0-ce17-b38469b05f40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Path to the Shakespeare text file on Google Drive\n","file_path = '/content/drive/My Drive/shakespeare.txt'\n","\n","# Reading the text file\n","with open(file_path, 'r', encoding='utf-8') as file:\n","    text = file.read().splitlines()\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hrYzc7KDfZXA","executionInfo":{"status":"ok","timestamp":1717792136450,"user_tz":-330,"elapsed":638,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}}},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","\n","# Initialize and fit tokenizer\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(text)\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","# Create sequences\n","input_sequence = []\n","for line in text:\n","    token_list = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequence.append(n_gram_sequence)\n","\n","# Padding sequences to ensure all are the same length\n","input_sequence = pad_sequences(input_sequence, padding='pre')\n","max_len = input_sequence.shape[1]  # Correctly calculating max_len here\n"]},{"cell_type":"code","source":["vocab_size = len(tokenizer.word_index) + 1  # Include +1 for zero padding\n"],"metadata":{"id":"Sv9slibeWBnG","executionInfo":{"status":"ok","timestamp":1717792140002,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ZCVx2_UdbUI0","executionInfo":{"status":"ok","timestamp":1717792143487,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}}},"outputs":[],"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input, Bidirectional\n","\n","def build_generator(vocab_size, max_len):\n","    model = Sequential([\n","        Embedding(vocab_size, 100, input_length=max_len-1),\n","        Bidirectional(LSTM(128, return_sequences=True)),\n","        Dropout(0.2),\n","        LSTM(128),\n","        Dense(vocab_size, activation='softmax')\n","    ])\n","    return model\n","\n","def build_discriminator(vocab_size, max_len):\n","    model = Sequential([\n","        Embedding(vocab_size, 100, input_length=max_len),\n","        Bidirectional(LSTM(128, return_sequences=True)),\n","        Dropout(0.2),\n","        LSTM(128),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    return model\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"0bpS6ZIpbYZ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717792151144,"user_tz":-330,"elapsed":5455,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}},"outputId":"4e0acc4d-e792-4fa0-9139-82dfa88fb221"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n","WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]}],"source":["# Now use these variables to build and compile your models\n","generator = build_generator(vocab_size, max_len)\n","\n","discriminator = build_discriminator(vocab_size, max_len)\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","# Compile the discriminator\n","discriminator.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Setup and compile the GAN\n","discriminator.trainable = False\n","gan_input = Input(shape=(max_len-1,))\n","gan_output = discriminator(generator(gan_input))\n","gan = Model(gan_input, gan_output)\n","gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"FYGsWAR0bZaD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717792157887,"user_tz":-330,"elapsed":2168,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}},"outputId":"1a08eaf5-57ea-4191-fa86-9fac6126b2f5"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n","WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]}],"source":["# noooooooooooooooo\n","# GAN Model where the discriminator's weights are frozen during generator training\n","discriminator.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n","discriminator.trainable = False\n","gan_input = Input(shape=(max_len-1,))\n","gan_output = discriminator(generator(gan_input))\n","gan = Model(gan_input, gan_output)\n","gan.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy')\n"]},{"cell_type":"code","source":["def train_gan(epochs=200, batch_size=32):\n","    for epoch in range(epochs):\n","        idx = np.random.randint(0, input_sequence.shape[0], batch_size)\n","        real_seqs = input_sequence[idx]\n","\n","        noise = np.random.normal(0, 1, (batch_size, max_len-1))\n","        fake_seqs = generator.predict(noise)\n","\n","        d_loss_real = discriminator.train_on_batch(real_seqs, np.ones((batch_size, 1)))\n","        d_loss_fake = discriminator.train_on_batch(fake_seqs, np.zeros((batch_size, 1)))\n","\n","        g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Discriminator Loss: {(d_loss_real + d_loss_fake) / 2}, Generator Loss: {g_loss}\")\n"],"metadata":{"id":"k2Xo7NHGXmaT","executionInfo":{"status":"ok","timestamp":1717792159592,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#### prev\n","def generate_text(seed_text, next_words=100):\n","    for _ in range(next_words):\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n","        predicted_probs = generator.predict(token_list, verbose=0)\n","        predicted_index = np.argmax(predicted_probs, axis=-1)[0]\n","        predicted_word = tokenizer.index_word.get(predicted_index, 'unknown')\n","        seed_text += \" \" + predicted_word\n","    return seed_text\n","\n","# Example seed text\n","generated_text = generate_text(\"adorned in shades of red\")\n","print(generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnSg7w-fXSta","executionInfo":{"status":"ok","timestamp":1717792197097,"user_tz":-330,"elapsed":5591,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}},"outputId":"3713c0a7-a26a-46f0-def1-9940e6e86da7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["adorned in shades of red send shake shake slide expressed teeth holds bevel fury directly garments' try hardest just just air hated hated plot hope repent fiery fiery fiery fiery homage infant's infant's guard guard guard tall tall twofold twofold wake wake wrecked wrecked wrecked beguile beguile harsh answer undivided presence cherubins sullied known known often but but but but bier sickle's reckoning flown kills flown worthy injury injury offender's resting imprisoned livery sullen looked excess disgraced vice bitter bitter nothing nothing sunset bosom compile ere ere title fickle fickle decay jade short ever ever hindmost substance substance loss loss watchman chips night sickle's mortality\n"]}]},{"cell_type":"code","source":["#EXP\n","\n","import numpy as np\n","\n","def sample(preds, temperature=1.0):\n","    \"\"\" Helper function to sample an index from a probability array. \"\"\"\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds + 1e-10) / temperature  # Adding a small number to avoid log(0)\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","def generate_text(seed_text, next_words=100, temperature=0.8):\n","    for _ in range(next_words):\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n","        predicted_probs = generator.predict(token_list, verbose=0)[0]\n","        next_index = sample(predicted_probs, temperature)  # Use temperature\n","        next_word = tokenizer.index_word.get(next_index, 'unknown')\n","        seed_text += \" \" + next_word\n","    return seed_text\n","\n","# Generate text with a bit of randomness\n","generated_text = generate_text(\"adorned in shades of red\", next_words=50, temperature=0.8)\n","print(generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESut1LajafFN","executionInfo":{"status":"ok","timestamp":1717792256141,"user_tz":-330,"elapsed":3357,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}},"outputId":"74873e1c-6760-46e6-83c9-377de4e81a2c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["adorned in shades of red adding bond buy raven any assured damasked oppression altered pluck philomel man's drown going left 'had unto fate weakness an pursuing judgement eat didst tempteth wolf able creation attaint birth ruined guides thence receive foregone surety prefiguring lords' wardrobe judgment simple shun threw whole fearful hated utmost untrimmed dross impute\n"]}]},{"cell_type":"code","source":["#EXPPP\n","def generate_sonnet_line(initial_words):\n","    return generate_text(initial_words, next_words=10, temperature=0.8)  # Generates one line\n","\n","def create_sonnet():\n","    lines = [generate_sonnet_line(\"The\") for _ in range(14)]\n","    sonnet_structure = \"\\n\".join([\n","        lines[0], lines[1], lines[4], lines[5],  # ABAB\n","        lines[2], lines[3], lines[6], lines[7],  # CDCD\n","        lines[8], lines[9], lines[12], lines[13],  # EFEF\n","        lines[10], lines[11]  # GG\n","    ])\n","    return sonnet_structure\n","\n","# Example usage to generate a sonnet\n","generated_sonnet = create_sonnet()\n","print(generated_sonnet)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEsO0bU0al5A","executionInfo":{"status":"ok","timestamp":1717792272848,"user_tz":-330,"elapsed":7295,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}},"outputId":"452c5d53-5cdf-464f-e1e8-c534eb9f2da1"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["The stirred dare immured without carry sap snow possessed stamp life's\n","The perusal mend suffers sadly slave heretic tempests adverse keep burthens\n","The tend dry dian's scorned less belied o beside excuse heaven's\n","The shall bosom hang car misplaced sight privilege stays sought splendour\n","The register seals clay vows advocate sport renew tells flatter esteem\n","The tables prescriptions groan stealing colour confounding sufferance moiety semblance clear\n","The touch sweet'st tears married invention miscalled beautiful days garments' mak'st\n","The hounds bounteous directed anger stole destroys meetness belied even freedom\n","The together veil blazon flesh i'll pleased compound another's proof becomes\n","The saved expiate accents resort jollity salve tells helen's erst bitterness\n","The sullen blind present strengthened statues fits valley torment shall feed'st\n","The stewards frowns gravity again closet exceed oppressed sit subject small\n","The respects augurs elsewhere o'erworn fed awake hidden intelligence offence thrusts\n","The herself thralled commit lov'st rondure spite loathsome perhaps me ocean\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('vader_lexicon')\n","nltk.download('punkt')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEm6uOmd8aqf","executionInfo":{"status":"ok","timestamp":1714548212344,"user_tz":-330,"elapsed":381,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}},"outputId":"5b5c9d07-d6da-4307-e4db-5c6091ce3e42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","\n","# Initialize sentiment analyzer\n","sia = SentimentIntensityAnalyzer()\n","\n","def calculate_sentiment(text):\n","    # Calculate sentiment scores\n","    sentiment_scores = sia.polarity_scores(text)\n","    return sentiment_scores\n","\n","def calculate_lexical_diversity(text):\n","    # Calculate lexical diversity\n","    words = word_tokenize(text)\n","    unique_words = set(words)\n","    lexical_diversity = len(unique_words) / len(words)\n","    return lexical_diversity\n","\n","def calculate_average_word_length(text):\n","    # Calculate average word length\n","    words = word_tokenize(text)\n","    total_chars = sum(len(word) for word in words)\n","    average_word_length = total_chars / len(words)\n","    return average_word_length\n","\n","def calculate_coherence(text):\n","    # Calculate coherence (placeholder implementation)\n","    coherence_score = 0.0  # Placeholder, needs implementation\n","    return coherence_score\n","\n","def check_iambic_pentameter(text):\n","    # Check iambic pentameter adherence (placeholder implementation)\n","    iambic_pentameter_adherence = False  # Placeholder, needs implementation\n","    return iambic_pentameter_adherence\n","\n","def check_format(text):\n","    # Check format adherence (placeholder implementation)\n","    format_adherence = False  # Placeholder, needs implementation\n","    return format_adherence\n","\n","# Example usage\n","generated_text = \"For having traffic with thy self alone\"\n","sentiment_scores = calculate_sentiment(generated_text)\n","lexical_diversity = calculate_lexical_diversity(generated_text)\n","average_word_length = calculate_average_word_length(generated_text)\n","coherence_score = calculate_coherence(generated_text)\n","iambic_pentameter_adherence = check_iambic_pentameter(generated_text)\n","format_adherence = check_format(generated_text)\n","\n","# Print results\n","print(\"Sentiment Scores:\", sentiment_scores)\n","print(\"Lexical Diversity:\", lexical_diversity)\n","print(\"Average Word Length:\", average_word_length)\n","print(\"Coherence Score:\", coherence_score)\n","print(\"Iambic Pentameter Adherence:\", iambic_pentameter_adherence)\n","print(\"Format Adherence:\", format_adherence)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4K0SlsCp8Sq0","executionInfo":{"status":"ok","timestamp":1714548216230,"user_tz":-330,"elapsed":619,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}},"outputId":"60d5987c-ce65-415c-da1e-2c81f301bc71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment Scores: {'neg': 0.25, 'neu': 0.75, 'pos': 0.0, 'compound': -0.25}\n","Lexical Diversity: 1.0\n","Average Word Length: 4.571428571428571\n","Coherence Score: 0.0\n","Iambic Pentameter Adherence: False\n","Format Adherence: False\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plotting the losses over epochs\n","plt.plot(history.history['loss'])\n","plt.title('Model Loss Over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"BEW8p2VzGyPb","executionInfo":{"status":"error","timestamp":1714549398582,"user_tz":-330,"elapsed":392,"user":{"displayName":"Sidra Azeem","userId":"09178067907816634899"}},"outputId":"9a1ee71c-5c67-4efd-9fcf-6307a8573e6e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'history' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-f52542492d56>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Plotting the losses over epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Loss Over Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}